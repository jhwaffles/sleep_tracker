{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\python311.zip', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\DLLs', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\Lib', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health', '', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jhuang\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\health\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor']\n"
     ]
    }
   ],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import regex as re\n",
    "#from categories import rules\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhuang\\OneDrive - Sutro Biopharma\\Documents 1\\Python_Scripts\\Health_App\\data\\sleep_data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhuang\\AppData\\Local\\Temp\\ipykernel_37720\\1707783407.py:79: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  oura_combined_df['timestamp'] = pd.to_datetime(oura_combined_df['timestamp'], errors='coerce')  # if it exists\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "data_dir = os.path.abspath(os.path.join(parent_dir, 'data'))\n",
    "file_path = os.path.join(data_dir, 'sleep_data.json')\n",
    "file_path_daily_sleep = os.path.join(data_dir, 'daily_sleep_data.json')\n",
    "\n",
    "print(file_path)\n",
    "# Open the file and load the JSON content\n",
    "with open(file_path, 'r') as file:\n",
    "    data_dict = json.load(file)  # Use json.load() for files\n",
    "\n",
    "# Extract the \"data\" field\n",
    "data = data_dict[\"data\"]\n",
    "\n",
    "# Separate single-point fields and time-series fields\n",
    "single_points = []\n",
    "time_series = []\n",
    "\n",
    "time_series_fields = ['hrv', 'heart_rate', 'movement_30_sec', 'sleep_phase_5_min']\n",
    "\n",
    "for record in data:\n",
    "    readiness=record.pop('readiness', {})\n",
    "    readiness_contributors = readiness.pop('contributors', {})\n",
    "    readiness_combined = {f\"readiness_{k}\": v for k, v in {**readiness_contributors, **readiness}.items()}\n",
    "    record.update(readiness_combined)\n",
    "    single_point = {k: v for k, v in record.items() if k not in time_series_fields}\n",
    "    single_points.append(single_point)\n",
    "    \n",
    "    for field in time_series_fields:\n",
    "        if field in record:\n",
    "            content = record[field]\n",
    "        # Handle different structures of time-series data\n",
    "            if isinstance(content, dict) and \"items\" in content:\n",
    "                interval = content.get(\"interval\", 1)  # Default interval to 1 second if not provided\n",
    "                start_timestamp = pd.to_datetime(content[\"timestamp\"])\n",
    "                for idx, value in enumerate(content[\"items\"]):\n",
    "                    if value is not None:  # Exclude nulls\n",
    "                        timestamp = start_timestamp + pd.to_timedelta(idx * interval, unit=\"s\")\n",
    "                        time_series.append({\n",
    "                            \"day\": record[\"day\"],\n",
    "                            \"field\": field,\n",
    "                            \"timestamp\": timestamp,\n",
    "                            \"value\": value\n",
    "                        })\n",
    "            elif isinstance(content, str):  # For movement_30_sec and sleep_phase_5_min\n",
    "                for idx, value in enumerate(content):\n",
    "                    timestamp = pd.to_datetime(record[\"bedtime_start\"]) + pd.to_timedelta(idx * 30, unit=\"s\")\n",
    "                    time_series.append({\n",
    "                        \"day\": record[\"day\"],\n",
    "                        \"field\": field,\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"value\": value\n",
    "                    })\n",
    "\n",
    "# Create DataFrames\n",
    "oura_data_single_points = pd.DataFrame(single_points)\n",
    "oura_data_single_points.rename(columns={'latency': 'latency_duration'}, inplace=True)\n",
    "\n",
    "oura_data_time_series = pd.DataFrame(time_series)\n",
    "\n",
    "with open(file_path_daily_sleep, 'r') as file:\n",
    "    daily_sleep_data_dict = json.load(file)\n",
    "\n",
    "daily_sleep_data = daily_sleep_data_dict[\"data\"]\n",
    "\n",
    "# Combine score info from daily sleep records with sleep_data.\n",
    "daily_sleep_records = []\n",
    "for record in daily_sleep_data:\n",
    "    contributors = record.pop(\"contributors\")\n",
    "    record.update(contributors)\n",
    "    daily_sleep_records.append(record)\n",
    "\n",
    "daily_sleep_df = pd.DataFrame(daily_sleep_records)\n",
    "\n",
    "oura_combined_df = pd.merge(daily_sleep_df, oura_data_single_points, on='day', how='left')\n",
    "\n",
    "#only count long sleep, since naps and short naps go to a daily score and we want one record per day \n",
    "oura_combined_df = oura_combined_df[oura_combined_df['type']=='long_sleep']\n",
    "oura_combined_df['day'] = pd.to_datetime(oura_combined_df['day'])\n",
    "oura_combined_df['timestamp'] = pd.to_datetime(oura_combined_df['timestamp'], errors='coerce')  # if it exists\n",
    "\n",
    "oura_combined_df['day_minus_one']=oura_combined_df['day']- pd.Timedelta(days=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove=['id_x','day','timestamp','id_y','sleep_score_delta','sleep_algorithm_version','type']\n",
    "oura_combined_df=oura_combined_df.drop(columns=columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_combined = os.path.join(data_dir, 'oura_combined.csv')\n",
    "output_path_timeseries = os.path.join(data_dir, 'oura_data_time_series.csv')\n",
    "\n",
    "oura_combined_df.to_csv(output_path_combined)\n",
    "oura_data_time_series.to_csv(output_path_timeseries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
